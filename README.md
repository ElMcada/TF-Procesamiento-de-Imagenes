<table>
<tr>
<td style="vertical-align: top; width: 100px; padding-right: 15px; border: none;">
<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ45DITH77up1n8tb7Bx2n7TO8tBq4I65ZIuw&s", align="left">
</td>
<td style="vertical-align: top; border: none;">
<h1>Universidad Peruana de Ciencias Aplicadas</h1>
<h2>1ACC0235 – Procesamiento de Imágenes</h2>
<p><strong>Sección:</strong> 12624</p>
<p><strong>Profesor:</strong> Peter Jonathan Montalvo Garcia</p>
</td>
</tr>
</table>

## Problematica escogida
   Al plantearnos este proyecto, partimos de una observación muy sencilla: a los niños pequeños muchas veces les cuesta poner en palabras lo que sienten. Es difícil para ellos decir "me siento frustrado" o "estoy ansioso", pero hemos notado que entienden y usan los emojis con mucha naturalidad. Basándonos en esto, pensamos en crear una herramienta educativa donde el niño pudiera demostrar que entiende una emoción dibujándola. Sin embargo, al intentar llevar esta idea a la práctica, nos encontramos con un problema técnico bastante grande: hacer que una computadora entienda los dibujos de un niño es mucho más difícil de lo que parece.
   
   El problema principal es que los niños no dibujan de forma perfecta ni uniforme. Si le pedimos a un niño que dibuje una cara de "sorpresa" , es probable que haga un círculo irregular y una boca muy grande, mientras que otro niño podría hacer solo garabatos que sugieran esa forma. Para nosotros como humanos es fácil ver la intención del dibujo, pero para la computadora, esos trazos son solo un montón de píxeles desordenados. Nos dimos cuenta de que no podíamos usar algoritmos de procesamiento de imágenes tradicionales porque cada niño tiene un estilo diferente y un nivel de motricidad distinto.

   Por eso, la problemática que realmente estamos resolviendo es la falta de flexibilidad de los sistemas tradicionales para evaluar la creatividad humana. Necesitamos un sistema que no juzgue el dibujo por qué tan preciso es geométricamente, sino que sea capaz de reconocer los rasgos generales, como una ceja fruncida para el enojo o una sonrisa para la felicidad, y asociarlos con el emoji correcto. Sin resolver este obstáculo de interpretación visual, sería imposible crear una aplicación que le diga al niño en tiempo real si su dibujo corresponde a la emoción que le pedimos.

